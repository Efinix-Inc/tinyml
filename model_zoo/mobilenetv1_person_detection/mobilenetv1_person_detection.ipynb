{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JD-98Cy2xGyN"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "##Update python version to python 3.7. This is required as latest python does not have tensorflow gpu 1.15 support. Tensorflow 1.xx is needed for this training\n",
        "!sudo apt-get install python3.7\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 3\n",
        "!sudo apt-get install python3.7-distutils\n",
        "!wget https://bootstrap.pypa.io/get-pip.py\n",
        "!sudo python3.7 get-pip.py\n",
        "!sudo apt-get install python3.7-distutils\n",
        "!pip install --upgrade \"protobuf<=3.20.1\"\n",
        "!pip install Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "#Get tensorflow model library\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "! pip install contextlib2\n",
        "import os\n",
        "new_python_path = (os.environ.get(\"PYTHONPATH\") or '') + \":models/research/slim\"\n",
        "%env PYTHONPATH=$new_python_path\n",
        "!pip install tf-slim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TF-Slim requires tensorflow 1.x to run. However, google colab no longer supports tensorflow 1.x. Workaround, we need to manually\n",
        "#install tensorflow 1.xx using pip. Ignore the error regarding gast version incompatibility\n",
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow-gpu==1.15\n",
        "!apt install --allow-change-held-packages libcudnn7=7.4.1.5-1+cuda10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfQ9npu3xl7w"
      },
      "outputs": [],
      "source": [
        "#Get dataset from visual wake words\n",
        "! python models/research/slim/download_and_convert_data.py \\\n",
        "--logtostderr \\\n",
        "--dataset_name=visualwakewords \\\n",
        "--dataset_dir=person_detection_dataset \\\n",
        "--foreground_class_of_interest='person' \\\n",
        "--small_object_area_threshold=0.005"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNQIMVO8xqsZ"
      },
      "outputs": [],
      "source": [
        "#Uncomment the three lines below to download pre-trained weight. The weight is trained up to 100K steps, thus it will continue from 100K points, up to 1 Million steps\n",
        "\n",
        "# !wget -O person_detection_train.zip https://www.dropbox.com/s/73u1ddqp8hmx8pt/person_detection_train.zip?dl=0\n",
        "# !unzip person_detection_train.zip\n",
        "# !rm -rf person_detection_train.zip\n",
        "\n",
        "#Train the model. Person detection model is trained for 1Million steps. \n",
        "! python models/research/slim/train_image_classifier.py \\\n",
        "    --alsologtostderr \\\n",
        "    --dataset_name=visualwakewords \\\n",
        "    --dataset_dir=person_detection_dataset \\\n",
        "    --dataset_split_name=train \\\n",
        "    --train_image_size=96 \\\n",
        "    --use_grayscale=True \\\n",
        "    --preprocessing_name=mobilenet_v1 \\\n",
        "    --model_name=mobilenet_v1_025 \\\n",
        "    --train_dir=person_detection_train \\\n",
        "    --save_summaries_secs=300 \\\n",
        "    --learning_rate=0.045 \\\n",
        "    --clone_on_cpu=True \\\n",
        "    --label_smoothing=0.1 \\\n",
        "    --learning_rate_decay_factor=0.98 \\\n",
        "    --num_epochs_per_decay=2.5 \\\n",
        "    --moving_average_decay=0.9999 \\\n",
        "    --batch_size=96 \\\n",
        "    --max_number_of_steps=1000000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjy52y95SYNt"
      },
      "outputs": [],
      "source": [
        "#Evaluate your model based on your checkpoints. Ensure that the checkpoint is based on your latest steps (e.g; model.ckpt-100000 for 100K steps)\n",
        "! python models/research/slim/eval_image_classifier.py \\\n",
        "    --alsologtostderr \\\n",
        "    --dataset_name=visualwakewords \\\n",
        "    --dataset_dir=person_detection_dataset \\\n",
        "    --dataset_split_name=val \\\n",
        "    --eval_image_size=96 \\\n",
        "    --use_grayscale=True \\\n",
        "    --preprocessing_name=mobilenet_v1 \\\n",
        "    --model_name=mobilenet_v1_025 \\\n",
        "    --train_dir=person_detection_train \\\n",
        "    --checkpoint_path=person_detection_train/model.ckpt-100000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCuli7xWSyuS"
      },
      "outputs": [],
      "source": [
        "#Generate model graph \n",
        "! python models/research/slim/export_inference_graph.py \\\n",
        "    --alsologtostderr \\\n",
        "    --dataset_name=visualwakewords \\\n",
        "    --image_size=96 \\\n",
        "    --use_grayscale=True \\\n",
        "    --model_name=mobilenet_v1_025 \\\n",
        "    --output_file=person_detection_graph.pb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cQup_7mS-bK"
      },
      "outputs": [],
      "source": [
        "#Generate frozen graph based on checkpoint. Ensure that the checkpoint is based on your latest steps (e.g; model.ckpt-100000 for 100K steps)\n",
        "! git clone -b r1.15 https://github.com/tensorflow/tensorflow.git\n",
        "! python tensorflow/tensorflow/python/tools/freeze_graph.py \\\n",
        "--input_graph=person_detection_graph.pb \\\n",
        "--input_checkpoint=person_detection_train/model.ckpt-100000 \\\n",
        "--input_binary=true \\\n",
        "--output_node_names=MobilenetV1/Predictions/Reshape_1 \\\n",
        "--output_graph=person_detection_frozen_graph.pb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeXlZHZmTBvD"
      },
      "outputs": [],
      "source": [
        "#Generate quantized model tflite\n",
        "import tensorflow.compat.v1 as tf\n",
        "import io\n",
        "import PIL\n",
        "import numpy as np\n",
        "\n",
        "def representative_dataset_gen():\n",
        "\n",
        "  record_iterator = tf.python_io.tf_record_iterator(path='person_detection_dataset/val.record-00000-of-00010')\n",
        "\n",
        "  for _ in range(250):\n",
        "    string_record = next(record_iterator)\n",
        "    example = tf.train.Example()\n",
        "    example.ParseFromString(string_record)\n",
        "    image_stream = io.BytesIO(example.features.feature['image/encoded'].bytes_list.value[0])\n",
        "    image = PIL.Image.open(image_stream)\n",
        "    image = image.resize((96, 96))\n",
        "    image = image.convert('L')\n",
        "    array = np.array(image)\n",
        "    array = np.expand_dims(array, axis=2)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    array = ((array / 127.5) - 1.0).astype(np.float32)\n",
        "    yield([array])\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_frozen_graph('person_detection_frozen_graph.pb',\n",
        "['input'], ['MobilenetV1/Predictions/Reshape_1'])\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "tflite_quant_model = converter.convert()\n",
        "open(\"person_detection_model.tflite\", \"wb\").write(tflite_quant_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNqAVSKxTlo8"
      },
      "outputs": [],
      "source": [
        "#Rename tflite model following <architecture>_<application>.tflite. This will be used in TinyML Generator for accelerator and model generation\n",
        "!mv person_detection_model.tflite mobilenetv1_person_detect.tflite "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Person Detection Demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
